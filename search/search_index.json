{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Configuration de GPU sur OpenShift","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Dans le monde de l'informatique moderne, l'optimisation des ressources est cruciale pour maximiser les performances et r\u00e9duire les co\u00fbts. Les GPU (Graphics Processing Units) jouent un r\u00f4le central dans de nombreuses applications, allant de l'intelligence artificielle au rendu graphique. Cependant, leur utilisation efficace dans un environnement de conteneurs comme OpenShift peut \u00eatre un d\u00e9fi. Ce document vous guidera \u00e0 travers les diff\u00e9rentes m\u00e9thodes de partage de GPU sur OpenShift, en mettant l'accent sur le Time Slicing, et vous montrera comment le configurer pour am\u00e9liorer l'utilisation des ressources GPU.</p> <p></p>"},{"location":"#pourquoi-partager-les-gpu","title":"Pourquoi Partager les GPU ?","text":"<p>Les GPU sont des ressources co\u00fbteuses et puissantes. Dans un cluster OpenShift, il est souvent n\u00e9cessaire de partager ces ressources entre plusieurs workloads pour maximiser leur utilisation. Voici les principales m\u00e9thodes de partage de GPU :</p>"},{"location":"#mig-multi-instance-gpu","title":"MIG (Multi-Instance GPU)","text":"<p>MIG permet de diviser un GPU physique en plusieurs instances plus petites, chacune avec ses propres ressources d\u00e9di\u00e9es. Cela permet \u00e0 plusieurs workloads de s'ex\u00e9cuter simultan\u00e9ment sur le m\u00eame GPU, am\u00e9liorant ainsi l'utilisation des ressources. Cependant, cette m\u00e9thode n\u00e9cessite un mat\u00e9riel compatible et peut \u00eatre complexe \u00e0 configurer.</p>"},{"location":"#vgpu-avec-openshift-virtualization","title":"vGPU avec OpenShift Virtualization","text":"<p>vGPU virtualise un GPU physique et le partage entre plusieurs machines virtuelles (VM). Chaque VM re\u00e7oit une partie des ressources du GPU, permettant une utilisation plus flexible. Cette m\u00e9thode est id\u00e9ale pour les environnements o\u00f9 les workloads n\u00e9cessitent une isolation compl\u00e8te des ressources GPU.</p>"},{"location":"#time-slicing-pour-openshift","title":"Time Slicing pour OpenShift","text":"<p>Time Slicing permet de partager un GPU entre plusieurs pods en allouant des tranches de temps d'ex\u00e9cution \u00e0 chaque pod. Contrairement \u00e0 MIG et vGPU, Time Slicing ne partitionne pas les ressources GPU mais permet une utilisation concurrente en r\u00e9partissant le temps d'ex\u00e9cution. Cette m\u00e9thode est particuli\u00e8rement utile pour les workloads qui n'ont pas besoin d'une utilisation continue du GPU.</p>"},{"location":"#configuration-du-mode-time-slicing","title":"Configuration du Mode Time Slicing","text":""},{"location":"#etape-1-deploiement-dun-job-de-test","title":"\u00c9tape 1 : D\u00e9ploiement d'un Job de Test","text":"<p>Pour commencer, d\u00e9ployons un job de test pour v\u00e9rifier que le Time Slicing n'est pas encore configur\u00e9. Ce job ne fonctionnera pas correctement car le Time Slicing n'est pas activ\u00e9.</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: dcgm-prof-tester\nspec:\n  parallelism: 4\n  template:\n    metadata:\n      labels:\n        app: dcgm-prof-tester\n    spec:\n      restartPolicy: OnFailure\n      containers:\n        - name: dcgmproftester12\n          image: nvcr.io/nvidia/cloud-native/dcgm:3.3.8-1-ubuntu22.04\n          command: [\"/usr/bin/dcgmproftester12\"]\n          args: [\"--no-dcgm-validation\", \"-t 1004\", \"-d 30\"]\n          resources:\n            limits:\n              nvidia.com/gpu: 1\n          securityContext:\n            capabilities:\n              add: [\"SYS_ADMIN\"]\n</code></pre> <p>Appliquez ce job sur OpenShift :</p> <pre><code>oc apply -f dcgm-prof-tester.yaml\n</code></pre> <p></p> <p>R\u00e9sultat attendu :</p> <p>Si vous n'avez q'un seul GPU vous devez voir qu'un seul job fonctionne et que les 3 autres echouent.</p>"},{"location":"#etape-2-recuperation-du-nom-du-gpu","title":"\u00c9tape 2 : R\u00e9cup\u00e9ration du Nom du GPU","text":"<p>Stockez le nom de votre GPU dans une variable d'environnement :</p> <pre><code>GPU_NAME=$(oc get node -o jsonpath='{.items[*].metadata.labels.nvidia\\.com/gpu\\.product}')\n</code></pre>"},{"location":"#etape-3-creation-de-la-configmap","title":"\u00c9tape 3 : Cr\u00e9ation de la ConfigMap","text":"<p>Cr\u00e9ez une ConfigMap pour configurer le Time Slicing. Cette ConfigMap sp\u00e9cifie les param\u00e8tres de partage pour le GPU.</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: device-plugin-config\n  namespace: nvidia-gpu-operator\ndata:\n  ${GPU_NAME}: |-\n    version: v1\n    sharing:\n      timeSlicing:\n        renameByDefault: false\n        resources:\n          - name: nvidia.com/gpu\n            replicas: 8\n</code></pre> <p>Ici avec \"replicas: 8\" on doit avoir 8 pod capable d'untiliser 1 gpu en mode time-slicing.</p>"},{"location":"#etape-4-patch-du-gpu-operator","title":"\u00c9tape 4 : Patch du GPU Operator","text":"<p>Appliquez la ConfigMap au GPU Operator pour activer le Time Slicing.</p> <pre><code>oc patch clusterpolicy gpu-cluster-policy \\\n    -n nvidia-gpu-operator --type merge \\\n    -p '{\"spec\": {\"devicePlugin\": {\"config\": {\"name\": \"device-plugin-config\"}}}}'\n</code></pre> <p>R\u00e9sultat attendu :</p> <pre><code>clusterpolicy.nvidia.com/gpu-cluster-policy patched\n</code></pre>"},{"location":"#etape-5-configuration-du-node","title":"\u00c9tape 5 : Configuration du Node","text":"<p>Appliquez ensuite le label correspondant :</p> <pre><code>oc label --overwrite node \\\n    --selector=nvidia.com/gpu.product=${GPU_NAME} \\\n    nvidia.com/device-plugin.config=${GPU_NAME}\n</code></pre> <p>R\u00e9sultat attendu :</p> <pre><code>node/&lt;node-name&gt; labeled\n</code></pre>"},{"location":"#etape-6-validation-de-la-configuration","title":"\u00c9tape 6 : Validation de la Configuration","text":"<p>V\u00e9rifiez que la capacit\u00e9 du GPU a bien \u00e9t\u00e9 mise \u00e0 jour :</p> <pre><code>oc get node --selector=nvidia.com/gpu.product=${GPU_NAME}-SHARED -o json | jq '.items[0].status.capacity'\n</code></pre> <p>Exemple R\u00e9sultat :</p> <pre><code>{\n  \"cpu\": \"28\",\n  \"devices.kubevirt.io/kvm\": \"1k\",\n  \"devices.kubevirt.io/tun\": \"1k\",\n  \"devices.kubevirt.io/vhost-net\": \"1k\",\n  \"ephemeral-storage\": \"975760576Ki\",\n  \"hugepages-1Gi\": \"0\",\n  \"hugepages-2Mi\": \"0\",\n  \"memory\": \"131711436Ki\",\n  \"nvidia.com/gpu\": \"8\",\n  \"pods\": \"250\"\n}\n</code></pre> <p>On observe notamment que la configuraiton \"nvidia.com/gpu\": \"8\" est maintenant appliqu\u00e9.</p>"},{"location":"#etape-7-relancer-le-job-de-test","title":"\u00c9tape 7 : Relancer le Job de Test","text":"<p>Relancez le job de test pour v\u00e9rifier que le Time Slicing est bien activ\u00e9.</p> <pre><code>oc delete job dcgm-prof-tester\noc apply -f dcgm-prof-tester.yaml\n</code></pre> <p>R\u00e9sultat attendu :</p> <p>Le job doit s'ex\u00e9cuter correctement avec plusieurs pods partageant le GPU sans erreur.</p> <p></p>"},{"location":"#conclusion","title":"Conclusion","text":"<p>En configurant le mode Time Slicing, vous optimisez l'utilisation des ressources GPU dans votre cluster OpenShift. Cette m\u00e9thode permet de partager efficacement les GPU entre plusieurs workloads, am\u00e9liorant ainsi les performances globales et r\u00e9duisant les co\u00fbts. Dans un prochain blogpost, nous explorerons comment configurer OpenShift avec vGPU pour une utilisation encore plus flexible des ressources GPU.</p>"}]}